---
title: "Naive Bayes Fake News"
Author: Shulaika van Kollenburg
Reviewer: Anne Dam
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
   html_notebook:
    toc: true
    toc_depth: 2
---





## Business Understanding
The Dataset of FakeNews consists of 20800 news articles and are labeled as unreliable or reliable to be distinguished from fake or real news. The goal of this assignment is to create a model that is able to detect fake news by making a prediction.




```{r}
library(tidyverse)
library(tm)
library(caret)
library(wordcloud)
library(e1071)
```


## Data Understanding
```{r}
url <- "https://raw.githubusercontent.com/HAN-M3DM-Data-Mining/data-mining-s1y2223-Anne1807/master/datasets/NB-fakenews.csv"
rawDF <- read_csv(url)
show_col_types="FALSE"
spec(rawDF)
```
```{r}
head(rawDF)
table(rawDF$label)
```
I removed the "1" because it was c("1","0", "1")
```{r}
rawDF$label <- rawDF$label %>% factor(levels = c("0", "1"), labels = c("Reliable", "Unreliable")) %>% relevel("Reliable")
class(rawDF$label)
```



```{r}
unreliable <- rawDF %>% filter(label == "Unreliable")
reliable <- rawDF %>% filter(label == "Reliable")





wordcloud(unreliable$title, max.words = 20, scale = c(4, 0.8), colors= c("indianred1","indianred2","indianred3","indianred"))






wordcloud(reliable$title, max.words = 20, scale = c(4, 0.8), colors= c("lightsteelblue1","lightsteelblue2","lightsteelblue3","lightsteelblue"))
```

## Data Preperation

```{r}
rawCorpus <- Corpus(VectorSource(rawDF$text))

```


I added %>% after tm_map(removePunctuation)
```{r}
inspect(rawCorpus[1:3])
cleanCorpus <- rawCorpus %>% tm_map(tolower)%>%
  tm_map(removeNumbers)%>%
  tm_map(removeWords, stopwords()) %>%
  tm_map(removePunctuation)%>%
  tm_map(stripWhitespace)
```

```{r}
cleanDTM <- cleanCorpus %>% DocumentTermMatrix
inspect(cleanDTM)
```

I changed head(rawDF) to head(trainIndex) because it took the wrong data to show
```{r}
set.seed(2345)
trainIndex <- createDataPartition(rawDF$label, p = .75,
                                  list = FALSE,
                                  times = 1)
head(trainIndex)
```


```{r}
trainDF <- rawDF[trainIndex, ]
testDF <- rawDF[-trainIndex, ]





# Apply split indices to Corpus
trainCorpus <- cleanCorpus[trainIndex]
testCorpus <- cleanCorpus[-trainIndex]





# Apply split indices to DTM
trainDTM <- cleanDTM[trainIndex, ]
testDTM <- cleanDTM[-trainIndex, ]
```

```{r}
freqWords <- trainDTM %>% findFreqTerms(7000)
trainDTM <-  DocumentTermMatrix(trainCorpus, list(dictionary = freqWords))
testDTM <-  DocumentTermMatrix(testCorpus, list(dictionary = freqWords))
```


i changed the labels from "reliable" "unreliable" to "no", "yes" because it just needs to say if it is in the data and not of it is reliable or unreliable 
```{r}
convert_counts <- function(x) {
  x <- ifelse(x > 0, 1, 0) %>% factor(levels = c(0,1), labels = c("No", "Yes"))
}

nColsDTM <- dim(trainDTM)[2]
trainDTM <- apply(trainDTM, MARGIN = 2, convert_counts)
testDTM <- apply(testDTM, MARGIN = 2, convert_counts)

head(trainDTM[,1:10])
```
## Modeling

I changed the word text to label so it first was trainDF$text and I changed it to trainDF$label 

```{r}
nbayesModel <-  naiveBayes(trainDTM, trainDF$label, laplace = 1)
```


I changed positive = "1" to positive = "reliable"
```{r}
predVec <- predict(nbayesModel, testDTM)
```
```{r}
confusionMatrix(predVec, testDF$label, positive = "Reliable", dnn = c("Prediction", "True"))
```
## Evaluation and Deployment

next time it would be useful to have a small explanation of what you did by every step. It would also be nice to see your conclusion and if the model is good or not.






